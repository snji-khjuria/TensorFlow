{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "epoch 0 Accuracy:- 0.3908\n",
      "epoch 1 Accuracy:- 0.6534\n",
      "epoch 2 Accuracy:- 0.7926\n",
      "epoch 3 Accuracy:- 0.8434\n",
      "epoch 4 Accuracy:- 0.8686\n",
      "epoch 5 Accuracy:- 0.8851\n",
      "epoch 6 Accuracy:- 0.8931\n",
      "epoch 7 Accuracy:- 0.8987\n",
      "epoch 8 Accuracy:- 0.9033\n",
      "epoch 9 Accuracy:- 0.907\n",
      "epoch 10 Accuracy:- 0.9103\n",
      "epoch 11 Accuracy:- 0.9129\n",
      "epoch 12 Accuracy:- 0.9146\n",
      "epoch 13 Accuracy:- 0.9167\n",
      "epoch 14 Accuracy:- 0.9187\n",
      "epoch 15 Accuracy:- 0.9201\n",
      "epoch 16 Accuracy:- 0.9211\n",
      "epoch 17 Accuracy:- 0.923\n",
      "epoch 18 Accuracy:- 0.9238\n",
      "epoch 19 Accuracy:- 0.9262\n",
      "epoch 20 Accuracy:- 0.9276\n",
      "epoch 21 Accuracy:- 0.9292\n",
      "epoch 22 Accuracy:- 0.93\n",
      "epoch 23 Accuracy:- 0.9319\n",
      "epoch 24 Accuracy:- 0.933\n",
      "epoch 25 Accuracy:- 0.934\n",
      "epoch 26 Accuracy:- 0.9347\n",
      "epoch 27 Accuracy:- 0.9355\n",
      "epoch 28 Accuracy:- 0.9367\n",
      "epoch 29 Accuracy:- 0.9371\n",
      "epoch 30 Accuracy:- 0.9378\n",
      "epoch 31 Accuracy:- 0.9385\n",
      "epoch 32 Accuracy:- 0.9394\n",
      "epoch 33 Accuracy:- 0.9401\n",
      "epoch 34 Accuracy:- 0.9407\n",
      "epoch 35 Accuracy:- 0.9414\n",
      "epoch 36 Accuracy:- 0.9421\n",
      "epoch 37 Accuracy:- 0.9428\n",
      "epoch 38 Accuracy:- 0.9432\n",
      "epoch 39 Accuracy:- 0.9442\n",
      "epoch 40 Accuracy:- 0.9449\n",
      "epoch 41 Accuracy:- 0.9459\n",
      "epoch 42 Accuracy:- 0.9467\n",
      "epoch 43 Accuracy:- 0.9471\n",
      "epoch 44 Accuracy:- 0.9473\n",
      "epoch 45 Accuracy:- 0.9476\n",
      "epoch 46 Accuracy:- 0.9476\n",
      "epoch 47 Accuracy:- 0.9482\n",
      "epoch 48 Accuracy:- 0.9485\n",
      "epoch 49 Accuracy:- 0.9493\n",
      "epoch 50 Accuracy:- 0.95\n",
      "epoch 51 Accuracy:- 0.9501\n",
      "epoch 52 Accuracy:- 0.9505\n",
      "epoch 53 Accuracy:- 0.9505\n",
      "epoch 54 Accuracy:- 0.9507\n",
      "epoch 55 Accuracy:- 0.9513\n",
      "epoch 56 Accuracy:- 0.9514\n",
      "epoch 57 Accuracy:- 0.952\n",
      "epoch 58 Accuracy:- 0.9522\n",
      "epoch 59 Accuracy:- 0.9526\n",
      "epoch 60 Accuracy:- 0.9528\n",
      "epoch 61 Accuracy:- 0.9531\n",
      "epoch 62 Accuracy:- 0.9534\n",
      "epoch 63 Accuracy:- 0.9541\n",
      "epoch 64 Accuracy:- 0.9541\n",
      "epoch 65 Accuracy:- 0.9543\n",
      "epoch 66 Accuracy:- 0.9544\n",
      "epoch 67 Accuracy:- 0.9544\n",
      "epoch 68 Accuracy:- 0.9545\n",
      "epoch 69 Accuracy:- 0.9548\n",
      "epoch 70 Accuracy:- 0.9551\n",
      "epoch 71 Accuracy:- 0.9554\n",
      "epoch 72 Accuracy:- 0.9557\n",
      "epoch 73 Accuracy:- 0.9559\n",
      "epoch 74 Accuracy:- 0.9558\n",
      "epoch 75 Accuracy:- 0.9558\n",
      "epoch 76 Accuracy:- 0.9561\n",
      "epoch 77 Accuracy:- 0.9564\n",
      "epoch 78 Accuracy:- 0.9566\n",
      "epoch 79 Accuracy:- 0.9566\n",
      "epoch 80 Accuracy:- 0.9566\n",
      "epoch 81 Accuracy:- 0.9568\n",
      "epoch 82 Accuracy:- 0.9569\n",
      "epoch 83 Accuracy:- 0.957\n",
      "epoch 84 Accuracy:- 0.9571\n",
      "epoch 85 Accuracy:- 0.9571\n",
      "epoch 86 Accuracy:- 0.9573\n",
      "epoch 87 Accuracy:- 0.9576\n",
      "epoch 88 Accuracy:- 0.9579\n",
      "epoch 89 Accuracy:- 0.9582\n",
      "epoch 90 Accuracy:- 0.9582\n",
      "epoch 91 Accuracy:- 0.9582\n",
      "epoch 92 Accuracy:- 0.9584\n",
      "epoch 93 Accuracy:- 0.9586\n",
      "epoch 94 Accuracy:- 0.9589\n",
      "epoch 95 Accuracy:- 0.959\n",
      "epoch 96 Accuracy:- 0.9592\n",
      "epoch 97 Accuracy:- 0.9594\n",
      "epoch 98 Accuracy:- 0.9595\n",
      "epoch 99 Accuracy:- 0.9599\n"
     ]
    }
   ],
   "source": [
    "#Single hidden layer neural network\n",
    "#do the essential imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#essential functions\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "#create the model function\n",
    "def model(X, w_h, w_o):\n",
    "    h = tf.nn.sigmoid(tf.matmul(X, w_h))\n",
    "    #don't take softmax here cost function does it for us\n",
    "    o = tf.matmul(h, w_o)\n",
    "    return o\n",
    "    \n",
    "#read the dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "#create the placeholders and ops\n",
    "#X's shape is batch X feature size\n",
    "#Y's shape is batch X output size\n",
    "FEATURE_SIZE      = 784\n",
    "HIDDEN_LAYER_SIZE = 40\n",
    "X                 = tf.placeholder(\"float\", [None, FEATURE_SIZE])\n",
    "Y                 = tf.placeholder(\"float\", [None, 10])\n",
    "w_h               = init_weights([FEATURE_SIZE, HIDDEN_LAYER_SIZE])\n",
    "w_o               = init_weights([HIDDEN_LAYER_SIZE, 10])\n",
    "\n",
    "# X = tf.placeholder(\"float\", [None, 784])\n",
    "# Y = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "# w_h = init_weights([784, 625]) # create symbolic variables\n",
    "# w_o = init_weights([625, 10])\n",
    "\n",
    "# py_x = model(X, w_h, w_o)\n",
    "\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y)) # compute costs\n",
    "# train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost) # construct an optimizer\n",
    "# predict_op = tf.argmax(py_x, 1)\n",
    "pr_y              = model(X, w_h, w_o)\n",
    "cost              = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pr_y, labels=Y))\n",
    "train_op          = tf.train.GradientDescentOptimizer(0.05).minimize(cost)\n",
    "predict_op        = tf.argmax(pr_y, 1)\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(100):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
    "            sess.run(train_op, feed_dict={X:trX[start:end], Y:trY[start:end]})\n",
    "        if i%1==0:\n",
    "            predictions = sess.run(predict_op, feed_dict={X:teX})\n",
    "            actuals     = np.argmax(teY, axis=1)\n",
    "            accuracy    = np.mean(predictions==actuals)\n",
    "            print(\"epoch \" + str(i) + \" Accuracy:- \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 Accuracy:- 0.785\n",
      "epoch 1 Accuracy:- 0.8845\n",
      "epoch 2 Accuracy:- 0.9059\n",
      "epoch 3 Accuracy:- 0.9198\n",
      "epoch 4 Accuracy:- 0.9317\n"
     ]
    }
   ],
   "source": [
    "def deepModelWithDropout(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden1, p_keep_hidden2):\n",
    "    # this network is the same as the previous one except with an extra hidden layer + dropout\n",
    "    #X->Dropout->h1->Dropout->h2->dropout->output logits\n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h))\n",
    "    h = tf.nn.dropout(h, p_keep_hidden1)\n",
    "    h2 = tf.nn.relu(tf.matmul(h, w_h2))\n",
    "    h2 = tf.nn.dropout(h2, p_keep_hidden2)\n",
    "    return tf.matmul(h2, w_o)\n",
    "\n",
    "FEATURE_SIZE=784\n",
    "OUTPUT_SIZE=10\n",
    "HIDDEN_LAYER_SIZE=625\n",
    "X = tf.placeholder(\"float\", [None, FEATURE_SIZE])\n",
    "Y = tf.placeholder(\"float\", [None, OUTPUT_SIZE])\n",
    "\n",
    "w_h  = init_weights([FEATURE_SIZE, HIDDEN_LAYER_SIZE])\n",
    "w_h2 = init_weights([HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE])\n",
    "w_o  = init_weights([HIDDEN_LAYER_SIZE, OUTPUT_SIZE])\n",
    "\n",
    "p_keep_input   = tf.placeholder(\"float\")\n",
    "p_keep_hidden1 = tf.placeholder(\"float\")\n",
    "p_keep_hidden2 = tf.placeholder(\"float\")\n",
    "pr_y           = deepModelWithDropout(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden1, p_keep_hidden2)\n",
    "\n",
    "cost       = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pr_y, labels=Y))\n",
    "train_op   = tf.train.GradientDescentOptimizer(0.05).minimize(cost)\n",
    "predict_op = tf.argmax(pr_y, 1)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(5):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
    "            sess.run(train_op, feed_dict={X:trX[start:end], Y:trY[start:end], p_keep_input:1.0,\n",
    "                                         p_keep_hidden1:0.8, p_keep_hidden2:0.5})\n",
    "        if i%1==0:\n",
    "            predictions = sess.run(predict_op, feed_dict={X:teX, p_keep_hidden1:1.0, p_keep_input:1.0,\n",
    "                                                         p_keep_hidden1:1.0, p_keep_hidden2:1.0})\n",
    "            actuals     = np.argmax(teY, axis=1)\n",
    "            accuracy    = np.mean(predictions==actuals)\n",
    "            print(\"epoch \" + str(i) + \" Accuracy:- \" + str(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
